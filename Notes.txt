What i've learned:

	- Regression
		- Linear regression
		- Robust regression (RANSAC)
		- Multiple linear regression
			- Dummy variable trap. Shouldn't have variables that predict each other. Can't distinguish between the effects of the coefficients. Always omit one dummy variable, it will be included in the constant coefficient. 
			- Backward elimination: 
				1) Select a significance level to stay in the model (e.g 5%).
				2) Fit the full model with all possible predictors.
				3) Consider the predictor with the highest P-value. If P > SL, go to step 4.
				4) Remove the predictor.
				5) Fit the model without this variable, repeat from step 3. When no variable matches in step 3 your model is ready.
			- Forward selection:
				1) Select a significance level to enter the model (e.g. 5%).
				2) Fit all simple regression models y ~ xn. Select the one with the lowest P-value.
				3) Keep this variable and fit all possible models with one extra predictor added to the one(s) you already have.
				4) Consider the predictor with the lowest P-value. If it's lower than the significance level, go to step 3, otherwise finish. 
			- Bidirectional elimination
				1) Select a significance level to enter and to stay. You could pick 5% for both. 
				2) Perform the next step of the forward selection (new variables must have a P value lower than the entry level).
				3) Perform ALL of the Backward Elimination steps (old variables must have a P value lower than the significance level to stay). Repeat from step 2. 
				4) No variables can enter and no old variables can leave. Then the model is done!
			- All possible models
				1) Select a criterion of goodness of fit(e.g. Akaike criterion)
				2) Construct all possible regression models, 2^n-1 total combinations
				3) Select the one with the best criterion
				Very resource consuming, 10 models => 1023 models.

	- Classification
		- Logistic regression
			- "State a likelyhood for a person to take action"
			- Sigmoid function
			- Used to predict probability (p-hat)
			- Y-value between 0 and 1, 0.42 => 42% probable
		
		- K-nearest neighbours
			- There's a step-by-step process which is applied to the data points you want to classify: 
				- 1) Choose the number of K neighbours (default = 5)
				- 2) Take the K nearest neighbours of the new data point, according to the Euclidean distance
				- 3) Among these K neighbours, count the number of data points in each category
				- 4) Assign the new data point to the category where you counted the most neigbours
			- The training data constitute the neighbours
			- Plot can show prediction boundry and prediction regions
			- Non-linear classifier

		- Support vector machines
			- Finds the best decision boundary that helps us classify our data points
			- The line is found by inspecting the maximum margin
			- The outmost "points" (actually vectors) of each class are called support vectors because they assist in finding the maximum margin
			- The line representing the maximum margin is called the maximum margin hyperplane
			- Other algorithms look at the most "appely apples", the heart of each class, to learn how a typical member of the class looks. Then they make predictions based on this experience.
			- SVMs look at "apples which are very much like oranges". That is, they look at members of a class, say A, who are very much alike members of another class, say B, and create their boundaries based on these observations. These extreme members are the support vectors. SVMs always look at the extreme cases. 
			- Some date is linearly separable, some are not. We can use different kernels in different situations.
			- Non-linearly separable problems:
				- Mapping to a higher dimension. For example, if you have points in one dimension you could center the boarder around 0 and then square the points, f = (x-5)^2. Projecting this function (line/hyperplane etc) into the original space gives us our separator.
				- Mapping to a higher dimension is quite demanding resource-wise. A lot of processing power is needed. 
				- The kernel trick helps us with this problem.
			- The kernel trick:
				- Gaussian RBF Kernel. K(X,L_i) = e ^ -((|X-L_i|^2)/(2*sigma^2)). RBF stands for radial basis function. Results in a three-dimensional "spike". The circumference can be projected back to a two-dimensional plane and used as a decision boundary. 
				- Sigma defines the circumference. 
				- Landmark defines the center of the circle.
				- Computation is still done in the lower-dimensional space
				- Several such kernels can be added, "Green if K(X,L_1) + K(X,L_2) > 0"
			- Kernel functions:
				- Gaussian RBF Kernel
				- Sigmoid Kernel 
				- Polynomial Kernel
		- Naïve Baye's classifier
			- Baye's theorem
				- Example: A lot of spanners, some coming from machine 1 and some from machine 2. Some work great, others are deffective. What is the probability of machine 2 producing a defective spanner? Machine 1 produces 30 wrenches/hour, machine 2 produces 20 wrenches/hour. Out of all of them, 1% are deffective. Out of all the deffective parts 50% came from machine 1, and 50% from machine 2. What is the probability that a part produced by machine 2 is defective?
				- P (A | B) = P(B | A) * P(A) / P(B)
				- A = defective, B = produced by machine 2
				- P(Defective | Produced by machine 2) = P(Produced by machine 2 | Defective) * P (Defective) / P(Produced by machine 2)
				- P(Defective | Produced by machine 2) = 0.5 * 0.01 / (20/50) = 1.25 %
				- P(Def | M1) = P(M1 | Def) * P(Def) / P(M1) = 0.5 * 0.01 / (30/50) = 0.0083333 ~ 0.83 % 
			- Plan of attack
				- Example: Features- salary & age, classes- walks & drives
				- Apply Baye's theorem twice
				- X represents the features
				- 1) P(Walks | X) = P(X | Walks) * P(Walks) / P(X)
				- Naming conventions:   - P(Walks) = Prior probability
										- P(X) = Marginal likelihood
										- P(X | Walks) = Likelihood
										- P(Walks | X) = Posterior probability 
				- 2) P(Drives | X) = P(X | Drives) * P(Drives) / P(X)
				- 3) Compare P(Walks | X) v.s. P(Drives | X) and decide
				- Thus, this is a probabilistic classifier
				- Calculations: 	- P(Walks | X)?
									- P(Walks) = Number of walkers / Total number of observations
									- P(X) = Draw circle around datapoint, remove your own datapoint temporarily, look at all the points inside the circle and deem them to be similar to the point we removed. The probability of X is the probability of a point being inside this circle. P(X) = Number of similar observations / Total observations
									- P(X | Walks) = Draw circle around observations, anything inside is similar, look only at the ones who are walking, what is the probability of a datapoint having similar features as the ones in the circle. P(X | Walks) = Number of similar observations among those who walk / Total number of walkers
									- P(Drives | X) = 1 - P(Walks | X), this is only because there are two classes, can be calculated in the same way.
			- Why "Naïve"?
				- Independence assumption
				- Assumes that the variables are independent. Are salary and age really independent?
				- We still apply it, thus naive.
			- P(X)
				- Number of similar observations / Total observations
				- Same in both step 1 & 2
				- Since we need to compare the probabilities against each other, and since they all include P(X), we can remove P(X). Simplification. If we want to calculate the actual value of say P(Walks | X), we can't reomve it. 
			- What happens when we have more than two classes? Take the maximum of the probabilities. Requires you to calculate several probabilities, can't just calculate one of them and then do 1 - ....
		
		- Decision trees
			- CART = Classification trees, regression trees
			- Regression => Real numbers
			- Classifications => Classes
			- We will focus on classification trees
			- Works by splitting up the data into slices. Does a number of splits.
			- The split is done such that the number of members of a class i maximized. 
			- The split is trying to minimize the entropy, there's some deep mathematics behind this. The easy way to think about it is that the splits are done such that on each side of the split the number of members of each class is maximized. 
			- Each "pocket" is called a leaf. The final ones are called terminal leafs.
			- The decision tree "asks questions" as it goes, based on the splits. "Is the point above or below of split 1?" -> "If above, to the left or right of split 2?"
			- Mathematical: 				X_2 < 60?
									Yes   /          \ No
									     /            \
									   X_1 < 70?
								Yes	  /       \ No
								     /         \
								  Class A      X_2 < 70? 
			- Trees can be very, very long. Sometimes you don't want to go all the way to the bottom. At a certain point, you can stop and simply look at the probabilities. Perhaps it's a 70% percent chance that a point belongs to class A when you still have numerous levels of the tree left. Then you might decide that this is "good enough" and end the computation.
			- It might not always be the case that there are two classes, nodes can thus have several children, and the type of questions can be very different.
			- Decision trees are actually an old method. Recently, they wre "reborn" with new methods, such as random forest and gradient boosting. Decision trees are very simple and not that useful on their own. However, combined with these methods, they can become very powerful.
			- The split aims to create homogenous groups
			- The algorithm tries to catch every case, and thus there is a risk of overfitting

		- Random forests
			- Ensemble learning
				- You take multiple machine learning algorithms and put them together to create a single, bigger, machine learning algorithm. The final algorithm weighs the partial algorithms against each other to make decisions. It could be several instances of the same algorithms but also different algorithms. 
			- Step-by-step process:
				1) Pick K random data points from the training set
				2) Build a decision tree associated to these K data points
				3) Choose the number of trees you want to build, and repeat steps 1 & 2
				4) For a new data point, make each of the trees predict the class of the point and assign the point to the class that wins the majority vote
			- Each tree might not be ideal, overall they perform very well. The algorithm leverages the power of the crowd. It relies on multiple trees. 
			- The power of numbers helps to get rid of certain errors and uncertainties. 
			- Used in kinect to understand where the bodyparts of people are and how they're moving
			- Play around with nr of trees to detect overfitting
			- Information gain = the reduced entropy
			- There's a risk of overfitting when using random forests. The algorithm tries to catch all cases, which causes it to "see things that aren't there", and can easily overfit the model.
		- False positives & false negatives
			- False positive = something that's predicted as positive (offer taken) but isn't
				- Also called a type I error
				- Something didn't happen, but we said that it would happen
			- False negative = something that's predicted as negative (offer declined) but isn't
				- Also called type II error
				- Something did happen, but we said that it wouldn't happen
		- Confusion Matrix
			- Columns are y-hat
			- Rows are y
			- cm[1,1] = Predicted true, actually true
			- cm[0,0] = Predicted false, actually false
			- cm[0,1] = Predicted true, actually false - false positives
			- cm[1,0] = Predicted false, actually true - false negatives
  	
	- Deep learning
		- Mimics the human brain
		- ~100 000 000 000 neurons in the human brain
		- We create artifical neural nets with nodes/neurons
		- Input layer, a node for each layer
		- Output layer, giving us a value
		- In between there are several hidden layers

		- The neuron:
			- The basic building blocks of neural networks
			- How can we recreate neurons in a machine?
			- A neuron by itself is pretty much useless
			- But when you have lots of them they can do 
			amazing stuff
			- Dendrites - receivers, Axons - transmitters
			- A neurons dendrites are connected to other neurons axons
			- The connections are called synapses, this is where the signal is passed
			- The neuron has a number of input signals and an output signal
			- The input layer represents the senses, i.e touch, smell, sight, hearing etc. 
			- The inputs are independent variables
			- One input is a single observation (one row) and the output is the output for this specific observation
			- The input variables needs to be standardized (mean of 0, variance of 1) or normalized. Additional reading: Efficient BackProp by Yann LeCun (1998)
			- Geoffrey Hinton
			- The output value can be continuous, binary or categorical (dummy values :-))
			- What happens in the neuron? It starts by summing up all the input values and multiplying them by a weight. I.e it takes the weighted sum.
			- After taking the weighted sum it applies the activation function
			- The value of the function is then passed on

		- The activation function:
			- Threshold function, just like a unit step. If the value is greater than 0 the function value is 1, if the value is smaller than 0 the function values i 0. 
			- Sigmoid function. 1 / (1 + e^-x). S-shaped. Approaches 0 for values smaller than 0, approaches 1 for values greater than 0.
			- Rectifier function. f(x) = max(x,0). Looks like a simple y=k*x line
			- Hyperbolic tangent. Similair to the Sigmoid function, but the functions values are in the range (-1,1)
			- Rectifier function in hidden layer and Sigmoid function in output layer is a common combination.

		- How do neural networks work?
			- Without a hidden layer, we basically just have a function in the output node applied to a number of input value. If this function was a linear regression we'd just have a linear regression...
			- The power in neural networks lies in the hidden layers, which provide extra accuracy/power
			- In this example we assume that the neural network is already trained. 
			- The inputs will be connected to the neurons via synapses. Each synapse will have a weight, some of which might be zero.
			- How could this be the case? In this example the area and the distance are relevant. Normally, the further away you get from the city the bigger the house you can get for a cheaper sum. This neuron could look specifically for area properties which are not that far from the city, but have large areas. The area is higher than the average compared to the other houses that close. If this critera is met, the activation function lits up. It doesn't really care about the bedrooms or the age.
			- Another example with a neuron that only looks at the area, the number of bedrooms and the age of the house. This neuron might've realized that in this specific city there are a lot of families with children that are looking for properties that are big and new. They want a low age, a high area and a high number of bedrooms and hence it's high valued. Therefore it doesn't care about the distance. The combination (!) of these parameters is what gives the neural network it's power. The neural network combines these three values into a new attribute and therefore it's more precise.
			- A third example. One neuron might've just picked up one parameter, the age. The price could drop for all houses under a 100 years, but when the house is over a 100 years the house could be more valuable. Here the rectifier function could be applied. It's 0 (no value) up until a 100 years. When a 100 years is passed this neuron contributes with a value. 
			- The neural network can pick up a lot of things that we can't realize ourselves.  
			- The hidden layer increases the flexibility of the neural network. It allows the neural network to look for very specific things. 

		- How do neural networks learn?
			- You provide inputs and outputs and let the neural network figure out the "rules" itself
			- We denote the actual value by y and the output value/the predicted value by y-hat.
			- In order to learn we compare y and y-hat. We do this by calculating the cost function. One such function is C = 0.5 * (y-hat - y) ^ 2
			- We want to minimize the cost function since the lower it is the closer y is to y-hat. 
			- We feed the information back into the neural network and based on that we update the weights.
			- We then feed the values back into the neural network, calculate the cost function, and then feed that information back. 
			- What happens with several rows? It's all the same perceptron, but feeded with multiple rows. 
			- One epok is when we go through a whole dataset. - We calculate y-hat for every row. For every row we have an actual value. Based on those differences we calulate the cost function C = sum(0.5 * (y-hat - y)^2)
			- After we have the full cost function we go back and update the weights. The weights are shared by all of the rows, that's why we sum everything up in the cost function, since it's shared.
			- Now we feed each row into the neural network again and repeat the process. 
			- This whole process is called back propagation.

		- Gradient descent
			- How can we minimize the cost function? 
			- We could brute force. Try a lot of weights and use the one that works the best. 
			- Doesn't work very well, requires a huge amount of resources. The curse of dimensionality!
			- Imagine 25 weights with a 1000 different possible weights. 1000^25 = 10^75. Sunway TaihuLight can do 93 PFLOPS. If we assume that one weight could be tried in one floating point operation. That would yield 10^75/(93*10^15) = 3.42 * 10^50 years. This is longer than the universe has existed. 
			- Instead of brute force we will use a method called gradient descent.
			- Pick a starting point. Look at the slope of the curve of the cost function. If the slope is negative we will go "downhill" on the curve. If the slope is positive we will go "uphill".
			- This allows us to find the best weights faster, i.e the lowest cost function. On the x-axis we have y-hat and on the y-axis we have the value of the cost function. 

		- Stochastic gradient descent
			- Gradient descent required the cost function to be convex
			- If it's not convex we could find the local minimum instead of the global minimum. 
			- To solve this we use stochastic gradient descent
			- Normal gradient descent is when we take all of our rows, plug them in to the neural network, calculate the cost function, and adjust the weights. 
			- In stochastic gradient descent we take a row, calculate the cost function, adjust the weights and then proceed with the next row. I.e we go row by row. The other form of gradient descent is called batch gradient descent.
			- The main two differences are that the stochastig gradient descent method helps you avoid the problem with finding local minimums. The reason for that is that the SGD has much higher fluctuations. It's more likely to find the global minimum. The other thing is that the SGD is faster. 
			- The batch gradient descent is deterministic, you will always receive the same result. SGD is stochastic, i.e random.

		- Backpropagation
			- During the process of backpropagation all the weights are updated. This is much easier than updating the individual weights independently.
			- The different steps of training the ANN with stochastic gradient descent.
			1) Randomly initialize the weights to small numbers close to 0
			2) Input the first observation of your dataset in the input layer, each feature in one input node.
			3) Forward propagation: from left to right, the neurons are activated in a way that the impact of each neuron's activation is limited by the weights. Propagate the activations until getting the predicted result y-hat.
			4) Compare the predicted result with the actual result. Measure the error using a cost function.
			5) Back-propagation: from right to left, the error is back-propagated. Update the weights according to how much they are responsible for the error. The learning rate decides by how much we update the weights. 
			6) Repeat steps 1 to 5 and update the weights after each observation (Reinforcement learning, in our case stochastic gradient descent). Or: repeat steps 1 to 5 but update the weights only after a batch of observations (Batch learning, gradient descent).
			7) When the whole training set passed through the ANN, that makes an epoch. Redo more epochs. 